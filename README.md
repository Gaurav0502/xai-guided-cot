<div align="center">
<h1>Explainability-Driven In-Context Learning</h1>
</div>

## Research Questions

1. Can LLMs effectively generate verbal reasoning from numerical feature importances?

2. Does providing this reasoning help in improving the prediction performance of few-shot chain of thought prompting?

3. How does the performance of the LLMs compare with that of tree-based models?

## Environment Setup

- Clone this repository.

```bash
git clone https://github.com/Gaurav0502/xai-guided-cot.git
```

- Install all packages in the ```requirements.txt``` file.

```bash
pip install -r requirements.txt
```

