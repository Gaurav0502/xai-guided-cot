{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec8bc181",
   "metadata": {},
   "source": [
    "# Explanability-Driven In-context Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cada729a",
   "metadata": {},
   "source": [
    "# Importing the required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f52666b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# modules used for data handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "\n",
    "# custom preprocessing modules\n",
    "from scripts.preprocess import preprocess_titanic\n",
    "\n",
    "# modules used for model handling\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# modules used for genari pipeline\n",
    "from scripts.pipeline import Pipeline\n",
    "from scripts.configs import Dataset, Model\n",
    "\n",
    "# modules used for env variables\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "WANDB_API_KEY = os.getenv(\"WANDB_API_KEY\")\n",
    "WANDB_PROJECT_NAME = os.getenv(\"WANDB_PROJECT_NAME\")\n",
    "PROJECT_NAME = os.getenv(\"PROJECT_NAME\")\n",
    "BUCKET_NAME = os.getenv(\"BUCKET_NAME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388546a1",
   "metadata": {},
   "source": [
    "## Default Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3bf4712",
   "metadata": {},
   "outputs": [],
   "source": [
    "explanable_model = XGBClassifier()\n",
    "tune_config_file = \"data/tune_config/xgb.json\"\n",
    "reasoning_gen_model = Model(\n",
    "    provider=\"together\",\n",
    "    name = \"deepseek-ai/DeepSeek-R1\",\n",
    "    temperature=0.6,\n",
    "    max_tokens=4096\n",
    ")\n",
    "objective_judge_model = Model(\n",
    "    provider=\"anthropic\",\n",
    "    name=\"claude-haiku-4-5\",\n",
    "    temperature=0.6,\n",
    "    max_tokens=4096\n",
    ")\n",
    "cot_model = Model(\n",
    "    provider=\"google\",\n",
    "    name=\"gemini-2.5-flash\",\n",
    "    temperature=0.0,\n",
    "    max_tokens=4096\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d5695d",
   "metadata": {},
   "source": [
    "## Test Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2890b3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(\n",
    "    name=\"titanic\",\n",
    "    path=\"data/datasets/titanic_small.csv\",\n",
    "    config_file_path=\"data/dataset_config/titanic_config.json\",\n",
    "    shap_vals_path=\"data/shap_values/titanic_shap.csv\",\n",
    "    preprocess_fn=preprocess_titanic,\n",
    "    target_col=\"Survived\",\n",
    "    labels={0: \"Did not survive\", 1: \"Survived\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "511432a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Pipeline(\n",
    "    dataset=dataset,\n",
    "    explanable_model=explanable_model,\n",
    "    tune_config_file=tune_config_file,\n",
    "    reasoning_gen_model=reasoning_gen_model,\n",
    "    objective_judge_model=objective_judge_model,\n",
    "    cot_model=cot_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ce42c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Titanic] Dropped 39 rows due to NaNs (kept 161 rows).\n",
      "Create sweep with ID: bngoq9v8\n",
      "Sweep URL: https://wandb.ai/gauravpendharkar/xai-guided-cot/sweeps/bngoq9v8\n",
      "[XAI-MODEL] Completed hyperparameter tuning.\n",
      "[XAI-MODEL] Trained model with best hyperparameters.\n",
      "[XAI-MODEL] Logged explanation data to data/dataset_config/titanic_config.json\n",
      "[XAI-MODEL] Explanation process completed.\n",
      "[Titanic] Dropped 39 rows due to NaNs (kept 161 rows).\n",
      "[GCS CLIENT] File data/batches/titanic_zero-shot_baseline_batches.jsonl uploaded to batch_inputs/gemini/titanic_zero-shot_baseline_batches.jsonl\n",
      "[ZERO-SHOT] Submitted Job: projects/54181826632/locations/us-east4/batchPredictionJobs/6150843143005667328\n",
      "[ZERO-SHOT] Output base dir: gs://xai_guided_cot_bucket/batch_outputs/gemini\n",
      "[ZERO-SHOT] projects/54181826632/locations/us-east4/batchPredictionJobs/6150843143005667328 state: JobState.JOB_STATE_QUEUED\n",
      "[ZERO-SHOT] projects/54181826632/locations/us-east4/batchPredictionJobs/6150843143005667328 state: JobState.JOB_STATE_QUEUED\n",
      "[ZERO-SHOT] projects/54181826632/locations/us-east4/batchPredictionJobs/6150843143005667328 state: JobState.JOB_STATE_RUNNING\n",
      "[ZERO-SHOT] projects/54181826632/locations/us-east4/batchPredictionJobs/6150843143005667328 state: JobState.JOB_STATE_RUNNING\n",
      "[ZERO-SHOT] projects/54181826632/locations/us-east4/batchPredictionJobs/6150843143005667328 state: JobState.JOB_STATE_RUNNING\n",
      "[ZERO-SHOT] projects/54181826632/locations/us-east4/batchPredictionJobs/6150843143005667328 state: JobState.JOB_STATE_RUNNING\n",
      "[ZERO-SHOT] projects/54181826632/locations/us-east4/batchPredictionJobs/6150843143005667328 state: JobState.JOB_STATE_RUNNING\n",
      "[ZERO-SHOT] projects/54181826632/locations/us-east4/batchPredictionJobs/6150843143005667328 state: JobState.JOB_STATE_RUNNING\n",
      "[ZERO-SHOT] projects/54181826632/locations/us-east4/batchPredictionJobs/6150843143005667328 state: JobState.JOB_STATE_RUNNING\n",
      "[ZERO-SHOT] projects/54181826632/locations/us-east4/batchPredictionJobs/6150843143005667328 state: JobState.JOB_STATE_RUNNING\n",
      "[ZERO-SHOT] projects/54181826632/locations/us-east4/batchPredictionJobs/6150843143005667328 state: JobState.JOB_STATE_RUNNING\n",
      "[ZERO-SHOT] projects/54181826632/locations/us-east4/batchPredictionJobs/6150843143005667328 state: JobState.JOB_STATE_SUCCEEDED\n",
      "[ZERO-SHOT] Final state: JobState.JOB_STATE_SUCCEEDED\n",
      "[GCS CLIENT] Downloaded batch_outputs/gemini/titanic_zero-shot_1765155754/prediction-model-2025-12-08T01:02:35.036750Z/predictions.jsonl to data/batch_outputs/titanic_zero-shot_baseline_predictions.jsonl.\n",
      "[POSTPROCESS] 0 requests were interrupted due to token limit and are ignored for evaluation.\n",
      "[Titanic] Dropped 39 rows due to NaNs (kept 161 rows).\n",
      "[Titanic] Dropped 39 rows due to NaNs (kept 161 rows).\n",
      "[GCS CLIENT] File data/batches/titanic_zero-shot-cot_baseline_batches.jsonl uploaded to batch_inputs/gemini/titanic_zero-shot-cot_baseline_batches.jsonl\n",
      "[ZERO-SHOT-COT] Submitted Job: projects/54181826632/locations/us-east4/batchPredictionJobs/6378837874141298688\n",
      "[ZERO-SHOT-COT] Output base dir: gs://xai_guided_cot_bucket/batch_outputs/gemini\n",
      "[ZERO-SHOT-COT] projects/54181826632/locations/us-east4/batchPredictionJobs/6378837874141298688 state: JobState.JOB_STATE_QUEUED\n",
      "[ZERO-SHOT-COT] projects/54181826632/locations/us-east4/batchPredictionJobs/6378837874141298688 state: JobState.JOB_STATE_QUEUED\n",
      "[ZERO-SHOT-COT] projects/54181826632/locations/us-east4/batchPredictionJobs/6378837874141298688 state: JobState.JOB_STATE_RUNNING\n",
      "[ZERO-SHOT-COT] projects/54181826632/locations/us-east4/batchPredictionJobs/6378837874141298688 state: JobState.JOB_STATE_RUNNING\n",
      "[ZERO-SHOT-COT] projects/54181826632/locations/us-east4/batchPredictionJobs/6378837874141298688 state: JobState.JOB_STATE_RUNNING\n",
      "[ZERO-SHOT-COT] projects/54181826632/locations/us-east4/batchPredictionJobs/6378837874141298688 state: JobState.JOB_STATE_RUNNING\n",
      "[ZERO-SHOT-COT] projects/54181826632/locations/us-east4/batchPredictionJobs/6378837874141298688 state: JobState.JOB_STATE_RUNNING\n",
      "[ZERO-SHOT-COT] projects/54181826632/locations/us-east4/batchPredictionJobs/6378837874141298688 state: JobState.JOB_STATE_RUNNING\n",
      "[ZERO-SHOT-COT] projects/54181826632/locations/us-east4/batchPredictionJobs/6378837874141298688 state: JobState.JOB_STATE_RUNNING\n",
      "[ZERO-SHOT-COT] projects/54181826632/locations/us-east4/batchPredictionJobs/6378837874141298688 state: JobState.JOB_STATE_SUCCEEDED\n",
      "[ZERO-SHOT-COT] Final state: JobState.JOB_STATE_SUCCEEDED\n",
      "[GCS CLIENT] Downloaded batch_outputs/gemini/titanic_zero-shot-cot_1765156120/prediction-model-2025-12-08T01:08:41.807168Z/predictions.jsonl to data/batch_outputs/titanic_zero-shot-cot_baseline_predictions.jsonl.\n",
      "[POSTPROCESS] 0 requests were interrupted due to token limit and are ignored for evaluation.\n",
      "[Titanic] Dropped 39 rows due to NaNs (kept 161 rows).\n",
      "[PIPELINE] Baseline metrics computed.\n",
      "Found best number of clusters: k=7 with silhouette score: 0.28442837590344316\n",
      "Chosen 7 diverse examples.\n",
      "[Titanic] Dropped 39 rows due to NaNs (kept 161 rows).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading file titanic_reasoning_batches.jsonl: 100%|██████████| 18.6k/18.6k [00:00<00:00, 34.5kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[REASON GENERATION] Current Status: BatchJobStatus.IN_PROGRESS\n",
      "[REASON GENERATION] Current Status: BatchJobStatus.IN_PROGRESS\n",
      "[REASON GENERATION] Current Status: BatchJobStatus.IN_PROGRESS\n",
      "[REASON GENERATION] Current Status: BatchJobStatus.COMPLETED\n",
      "[REASON GENERATION] Batch completed successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file titanic_reasoning_predictions.jsonl: 100%|██████████| 52.0k/52.0k [00:00<00:00, 26.9MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[REASON GENERATION] Batch outputs downloaded to data/batch_outputs/titanic_reasoning_predictions.jsonl\n",
      "[PIPELINE] Reasoning generation completed.\n",
      "[Titanic] Dropped 39 rows due to NaNs (kept 161 rows).\n",
      "[OBJECTIVE JUDGE] Submitted batch with id: msgbatch_019CHTtjiLir3HpUDR3oUE8M\n",
      "[OBJECTIVE JUDGE] Batch msgbatch_019CHTtjiLir3HpUDR3oUE8M is still processing...\n",
      "[OBJECTIVE JUDGE] Batch msgbatch_019CHTtjiLir3HpUDR3oUE8M is still processing...\n",
      "[OBJECTIVE JUDGE] Batch msgbatch_019CHTtjiLir3HpUDR3oUE8M has completed processing.\n",
      "[OBJECTIVE JUDGE] Batch result types: {'succeeded': 7, 'errored': 0, 'expired': 0}\n",
      "[OBJECTIVE JUDGE] Saved evaluations to data/batch_outputs/titanic_objective_judge_evaluations.jsonl\n",
      "[PIPELINE] Objective judge evaluation completed.\n",
      "[Titanic] Dropped 39 rows due to NaNs (kept 161 rows).\n",
      "[GCS CLIENT] File data/batches/titanic_icl_batches.jsonl uploaded to batch_inputs/gemini/titanic_icl_batches.jsonl\n",
      "[ICL CLASSIFIER] Submitted Job: projects/54181826632/locations/us-east4/batchPredictionJobs/7239025402969063424\n",
      "[ICL CLASSIFIER] Output base dir: gs://xai_guided_cot_bucket/batch_outputs/gemini/titanic_cot_1765156796/\n",
      "[ICL CLASSIFIER] projects/54181826632/locations/us-east4/batchPredictionJobs/7239025402969063424 state: JobState.JOB_STATE_QUEUED\n",
      "[ICL CLASSIFIER] projects/54181826632/locations/us-east4/batchPredictionJobs/7239025402969063424 state: JobState.JOB_STATE_RUNNING\n",
      "[ICL CLASSIFIER] projects/54181826632/locations/us-east4/batchPredictionJobs/7239025402969063424 state: JobState.JOB_STATE_RUNNING\n",
      "[ICL CLASSIFIER] projects/54181826632/locations/us-east4/batchPredictionJobs/7239025402969063424 state: JobState.JOB_STATE_RUNNING\n",
      "[ICL CLASSIFIER] projects/54181826632/locations/us-east4/batchPredictionJobs/7239025402969063424 state: JobState.JOB_STATE_RUNNING\n",
      "[ICL CLASSIFIER] projects/54181826632/locations/us-east4/batchPredictionJobs/7239025402969063424 state: JobState.JOB_STATE_SUCCEEDED\n",
      "[ICL CLASSIFIER] Final state: JobState.JOB_STATE_SUCCEEDED\n",
      "[GCS CLIENT] Downloaded batch_outputs/gemini/titanic_cot_1765156796/prediction-model-2025-12-08T01:19:57.482547Z/predictions.jsonl to data/batch_outputs/titanic_cot_predictions.jsonl.\n",
      "[PIPELINE] ICL classification with COT completed.\n",
      "[POSTPROCESS] 0 requests were interrupted due to token limit and are ignored for evaluation.\n",
      "[Titanic] Dropped 39 rows due to NaNs (kept 161 rows).\n",
      "[PIPELINE] Evaluation of COT predictions completed.\n",
      "[PIPELINE] Pipeline run completed.\n"
     ]
    }
   ],
   "source": [
    "llm.run(baseline=True, objective_judge=True, cot_ablation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b87b6ad0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'zero_shot_baseline': {'xgboost': {'accuracy': 0.8484848484848485,\n",
       "   'macro_f1_score': 0.8331648129423661},\n",
       "  'zero-shot-prompting': {'macro_f1_score': 0.7954545454545454,\n",
       "   'accuracy': 0.8181818181818182}},\n",
       " 'zero_shot_cot_ablation': {'xgboost': {'accuracy': 0.8484848484848485,\n",
       "   'macro_f1_score': 0.8331648129423661},\n",
       "  'zero-shot-cot': {'macro_f1_score': 0.5909090909090909,\n",
       "   'accuracy': 0.6363636363636364}},\n",
       " 'reasoning': {60: 'The model correctly predicts that the passenger did not survive (predicted label 0 matches ground truth 0.0). The SHAP values reveal that the strongest negative contributions come from Sex (0.0, male) at -1.49 and Pclass (3.0, third class) at -0.996, aligning with historical trends where males and lower-class passengers had lower survival rates. Age (21.0) further reduces survival probability with a SHAP of -0.312, as young adult males were less prioritized during evacuation. Although having no siblings/spouses (SibSp=0.0) contributes positively (SHAP +0.446), this is outweighed by the dominant negative features. Minor contributions from Parch, Fare, and Embarked do not alter the outcome. Cumulatively, these factors—especially high-impact features like Sex (global importance 0.552) and Pclass (0.117)—drive the prediction toward non-survival, resulting in a total SHAP value of approximately -2.376, which strongly suppresses the log-odds below the decision threshold.',\n",
       "  80: \"The model correctly predicts non-survival (0) for this passenger. The key negative contributors are Sex (male, SHAP = -1.318) and Pclass (3rd class, SHAP = -1.302), which align with historical patterns where males and lower-class passengers had reduced survival odds. These are further reinforced by SibSp (4 siblings/spouses, SHAP = -0.747), indicating a large family likely in third class, and Fare (39.69, SHAP = -0.455), which may reflect a group ticket cost rather than luxury. The positive influence of Age (16 years, SHAP = +0.778) partially offsets this, as younger passengers had higher priority, but not sufficiently to overcome the cumulative negative impact. Minor contributions from Parch (1 parent/child, SHAP = +0.133) and Embarked (Southampton, SHAP = +0.036) were negligible. The net SHAP sum (-2.875) strongly shifts the prediction away from survival, consistent with the passenger's actual fate.\",\n",
       "  59: 'The model correctly predicted survival (label 1) for this passenger, aligning with the ground truth label of 1.0. The prediction is driven primarily by the passenger\\'s gender (Sex=1.0, female), which has the highest SHAP value (2.08) and is the most important feature globally (importance 0.55), strongly favoring survival due to the \"women and children first\" protocol. The age of 19 years (SHAP 0.86) further supports survival, as young adults had better mobility. Having no siblings/spouses (SibSp=0.0, SHAP 0.46) also contributed positively, potentially enabling faster evacuation. Although third-class travel (Pclass=3.0, SHAP -1.22) significantly reduced survival chances due to restricted lifeboat access, the combined positive effects of gender, age, and SibSp outweighed this negative factor. Minor contributions from fare (SHAP 0.19) and negligible impacts from Parch (SHAP -0.01) and Embarked (SHAP -0.07) did not alter the outcome. Overall, the net SHAP value of approximately 2.29 decisively pushed the prediction above the threshold for survival.',\n",
       "  134: \"The model predicted non-survival (0) for this passenger, contrasting with the ground truth survival (1). Key feature contributions were analyzed using SHAP values, where positive values increase survival likelihood and negative values decrease it. The passenger's male gender (Sex=0) contributed strongly against survival (-1.40 SHAP), consistent with historical evacuation priorities. Being 49 years old (Age) further reduced survival probability (-0.93 SHAP), as adults had lower rescue priority. While 1st-class status (Pclass=1) strongly favored survival (+1.74 SHAP) and the higher fare (Fare=56.93) provided moderate support (+0.80 SHAP), these positive factors were insufficient to offset the substantial negative impact of gender and age. Embarkation location (Embarked=1) and family size features (SibSp=1, Parch=0) provided minor negative contributions. The cumulative SHAP effect was negative (-0.26), overwhelming the baseline survival probability and resulting in a non-survival prediction. This misprediction suggests the model overemphasized demographic risk factors despite countervailing privileges from higher socioeconomic status in this case.\",\n",
       "  78: \"The model correctly predicted that the passenger did not survive (predicted label 0 matches ground truth 0.0). Key contributions came from the passenger's age (38 years), which strongly reduced survival likelihood with a SHAP value of -1.8259, and fare (13 units), which further decreased survival probability with a SHAP value of -0.6094. Although the passenger being male (Sex=1.0) contributed positively (SHAP: +2.1648)—an unexpected effect given historical context—this was outweighed by the strong negative impacts of age and fare, along with smaller negative contributions from Pclass (2nd class, SHAP: -0.0325) and Parch (no children/parents, SHAP: -0.0630). The cumulative effect of these factors, particularly the dominant negative influence of age, resulted in the model's prediction of non-survival.\",\n",
       "  16: \"The model correctly predicted survival (1) for this passenger, aligning with the ground truth label (1.0). The prediction is driven by the combined SHAP contributions: First-class travel (Pclass=1.0) provides the strongest positive push (+1.87) due to priority evacuation access. Though being male (Sex=0.0) reduces survival likelihood (-1.39), this is counterbalanced by the high fare paid (Fare=52.55, +0.95), indicating luxury-class resources. The passenger's age (42.0) contributes moderately positively (+0.49), possibly reflecting prime-age resilience. Embarkation port (Embarked=0.0, likely Cherbourg) adds a minor survival boost (+0.20). While traveling with one sibling/spouse (SibSp=1.0, -0.12) and no parents/children (Parch=0.0, -0.05) slightly reduce odds, the net SHAP sum (≈1.96) decisively favors survival. The aggregate effect of premium travel conditions (Pclass, Fare) outweighs gender-based risks, resulting in the correct survival prediction.\",\n",
       "  41: 'The model correctly predicted that the passenger did not survive (label 0), aligning with the ground truth. Key features driving this prediction include Sex (0.0, male) and Pclass (3.0, third class), which had the strongest negative SHAP values (-1.303 and -1.026, respectively), heavily reducing survival probability. These features are the most globally important (Sex importance: 0.552, Pclass: 0.117). Additional negative contributions came from SibSp (1.0, -0.738 SHAP) and Fare) (7.0458, -0.261 SHAP), reflecting the risk associated with traveling with siblings/spouses and low ticket cost. Though Age (29.0) and Embarked (0.0) provided slight positive SHAP values (0.146 and 0.155), they were insufficient to offset the dominant negative influences. The cumulative effect of these factors—particularly male gender and third-class status—resulted in a clear prediction of non-survival.'},\n",
       " 'llm_as_judge': {60: {'faithfulness': 5.0,\n",
       "   'consistency': 5.0,\n",
       "   'coherence': 5.0},\n",
       "  80: {'faithfulness': 5.0, 'consistency': 5.0, 'coherence': 5.0},\n",
       "  59: {'faithfulness': 5.0, 'consistency': 5.0, 'coherence': 5.0},\n",
       "  134: {'faithfulness': 5.0, 'consistency': 4.75, 'coherence': 4.75},\n",
       "  78: {'faithfulness': 4.5, 'consistency': 4.0, 'coherence': 4.75},\n",
       "  16: {'faithfulness': 5.0, 'consistency': 4.75, 'coherence': 4.75},\n",
       "  41: {'faithfulness': 4.75, 'consistency': 4.75, 'coherence': 4.75}},\n",
       " 'cot': {'xgboost': {'accuracy': 0.8484848484848485,\n",
       "   'macro_f1_score': 0.8331648129423661},\n",
       "  'xai-guided-cot': {'macro_f1_score': 0.7847157502329916,\n",
       "   'accuracy': 0.7878787878787878}}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db1ec42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
