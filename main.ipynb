{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec8bc181",
   "metadata": {},
   "source": [
    "# Explanability-Driven In-context Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cada729a",
   "metadata": {},
   "source": [
    "# Importing the required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f52666b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hongyili/anaconda3/envs/6998final/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# modules used for data handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "\n",
    "# modules used for modeling\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# user-defined modules\n",
    "\n",
    "from scripts.configs import Dataset, Model\n",
    "from scripts.preprocess import preprocess_titanic\n",
    "from scripts.postprocess import (parse_reasoning_llm_results, parse_baseline_llm_results, summarize_baseline_results)\n",
    "from scripts.prompt_generator import (zero_shot_prompt_generator, \n",
    "                                      reasoning_generator_prompt,\n",
    "                                      objective_judge_prompt_generator)\n",
    "\n",
    "from scripts.explanable_tree_model import ExplainableModel\n",
    "from scripts.zero_shot_baseline import ZeroShotBaseline\n",
    "from scripts.diverse_examples import get_diverse_examples\n",
    "from scripts.reason_generation import ReasonGenerator\n",
    "from scripts.objective_judge import ObjectiveJudge\n",
    "\n",
    "# modules used for env variables\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "WANDB_API_KEY = os.getenv(\"WANDB_API_KEY\")\n",
    "WANDB_PROJECT_NAME = os.getenv(\"WANDB_PROJECT_NAME\")\n",
    "PROJECT_NAME = os.getenv(\"PROJECT_NAME\")\n",
    "BUCKET_NAME = os.getenv(\"BUCKET_NAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bf4712",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_dataset = Dataset(\n",
    "    name=\"titanic\",\n",
    "    path=\"data/datasets/titanic.csv\",\n",
    "    config_file_path=\"data/dataset_config/titanic_config.json\",\n",
    "    preprocess_fn=preprocess_titanic,\n",
    "    shap_vals_path=\"data/shap_values/titanic_shap.csv\",\n",
    "    target_col=\"Survived\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8dce0b",
   "metadata": {},
   "source": [
    "# Tree Model Performance (XGBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15773701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Titanic] Dropped 179 rows due to NaNs (kept 712 rows).\n",
      "Create sweep with ID: yc32vi2s\n",
      "Sweep URL: https://wandb.ai/gauravpendharkar/xai-guided-cot/sweeps/yc32vi2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 1jdbwahq with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.27854961660395194\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_depth: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmin_child_weight: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_estimators: 339\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \treg_lambda: 0.08415814901838715\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsubsample: 0.6877590380220275\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmitugaurav15\u001b[0m (\u001b[33mgauravpendharkar\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'xai-guided-cot' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/gauravpendharkar/xai-guided-cot/wandb/run-20251201_201907-1jdbwahq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/gauravpendharkar/xai-guided-cot/runs/1jdbwahq' target=\"_blank\">pretty-sweep-1</a></strong> to <a href='https://wandb.ai/gauravpendharkar/xai-guided-cot' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/gauravpendharkar/xai-guided-cot/sweeps/yc32vi2s' target=\"_blank\">https://wandb.ai/gauravpendharkar/xai-guided-cot/sweeps/yc32vi2s</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/gauravpendharkar/xai-guided-cot' target=\"_blank\">https://wandb.ai/gauravpendharkar/xai-guided-cot</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/gauravpendharkar/xai-guided-cot/sweeps/yc32vi2s' target=\"_blank\">https://wandb.ai/gauravpendharkar/xai-guided-cot/sweeps/yc32vi2s</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/gauravpendharkar/xai-guided-cot/runs/1jdbwahq' target=\"_blank\">https://wandb.ai/gauravpendharkar/xai-guided-cot/runs/1jdbwahq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Detected [anthropic, google.genai] in use.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Use W&B Weave for improved LLM call tracing. Install Weave with `pip install weave` then add `import weave` to the top of your script.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: For more information, check out the docs at: https://weave-docs.wandb.ai/\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>accuracy_std</td><td>▁</td></tr><tr><td>f1_macro</td><td>▁</td></tr><tr><td>f1_macro_std</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.79801</td></tr><tr><td>accuracy_std</td><td>0.03593</td></tr><tr><td>f1_macro</td><td>0.7885</td></tr><tr><td>f1_macro_std</td><td>0.03672</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">pretty-sweep-1</strong> at: <a href='https://wandb.ai/gauravpendharkar/xai-guided-cot/runs/1jdbwahq' target=\"_blank\">https://wandb.ai/gauravpendharkar/xai-guided-cot/runs/1jdbwahq</a><br> View project at: <a href='https://wandb.ai/gauravpendharkar/xai-guided-cot' target=\"_blank\">https://wandb.ai/gauravpendharkar/xai-guided-cot</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251201_201907-1jdbwahq/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9wwfoqxj with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.1139874026806906\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_depth: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmin_child_weight: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_estimators: 400\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \treg_lambda: 0.9535245332694242\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsubsample: 0.7282078377467783\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'xai-guided-cot' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/gauravpendharkar/xai-guided-cot/wandb/run-20251201_201912-9wwfoqxj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/gauravpendharkar/xai-guided-cot/runs/9wwfoqxj' target=\"_blank\">cosmic-sweep-2</a></strong> to <a href='https://wandb.ai/gauravpendharkar/xai-guided-cot' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/gauravpendharkar/xai-guided-cot/sweeps/yc32vi2s' target=\"_blank\">https://wandb.ai/gauravpendharkar/xai-guided-cot/sweeps/yc32vi2s</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/gauravpendharkar/xai-guided-cot' target=\"_blank\">https://wandb.ai/gauravpendharkar/xai-guided-cot</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/gauravpendharkar/xai-guided-cot/sweeps/yc32vi2s' target=\"_blank\">https://wandb.ai/gauravpendharkar/xai-guided-cot/sweeps/yc32vi2s</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/gauravpendharkar/xai-guided-cot/runs/9wwfoqxj' target=\"_blank\">https://wandb.ai/gauravpendharkar/xai-guided-cot/runs/9wwfoqxj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>accuracy_std</td><td>▁</td></tr><tr><td>f1_macro</td><td>▁</td></tr><tr><td>f1_macro_std</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.81731</td></tr><tr><td>accuracy_std</td><td>0.03909</td></tr><tr><td>f1_macro</td><td>0.80587</td></tr><tr><td>f1_macro_std</td><td>0.03998</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">cosmic-sweep-2</strong> at: <a href='https://wandb.ai/gauravpendharkar/xai-guided-cot/runs/9wwfoqxj' target=\"_blank\">https://wandb.ai/gauravpendharkar/xai-guided-cot/runs/9wwfoqxj</a><br> View project at: <a href='https://wandb.ai/gauravpendharkar/xai-guided-cot' target=\"_blank\">https://wandb.ai/gauravpendharkar/xai-guided-cot</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251201_201912-9wwfoqxj/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: b3lg0oto with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.008197120293719072\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_depth: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmin_child_weight: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_estimators: 471\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \treg_lambda: 0.2404745471506243\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsubsample: 0.8750482603977314\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'xai-guided-cot' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/gauravpendharkar/xai-guided-cot/wandb/run-20251201_201918-b3lg0oto</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/gauravpendharkar/xai-guided-cot/runs/b3lg0oto' target=\"_blank\">peachy-sweep-3</a></strong> to <a href='https://wandb.ai/gauravpendharkar/xai-guided-cot' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/gauravpendharkar/xai-guided-cot/sweeps/yc32vi2s' target=\"_blank\">https://wandb.ai/gauravpendharkar/xai-guided-cot/sweeps/yc32vi2s</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/gauravpendharkar/xai-guided-cot' target=\"_blank\">https://wandb.ai/gauravpendharkar/xai-guided-cot</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/gauravpendharkar/xai-guided-cot/sweeps/yc32vi2s' target=\"_blank\">https://wandb.ai/gauravpendharkar/xai-guided-cot/sweeps/yc32vi2s</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/gauravpendharkar/xai-guided-cot/runs/b3lg0oto' target=\"_blank\">https://wandb.ai/gauravpendharkar/xai-guided-cot/runs/b3lg0oto</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>accuracy_std</td><td>▁</td></tr><tr><td>f1_macro</td><td>▁</td></tr><tr><td>f1_macro_std</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.80677</td></tr><tr><td>accuracy_std</td><td>0.0468</td></tr><tr><td>f1_macro</td><td>0.79149</td></tr><tr><td>f1_macro_std</td><td>0.05384</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">peachy-sweep-3</strong> at: <a href='https://wandb.ai/gauravpendharkar/xai-guided-cot/runs/b3lg0oto' target=\"_blank\">https://wandb.ai/gauravpendharkar/xai-guided-cot/runs/b3lg0oto</a><br> View project at: <a href='https://wandb.ai/gauravpendharkar/xai-guided-cot' target=\"_blank\">https://wandb.ai/gauravpendharkar/xai-guided-cot</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251201_201918-b3lg0oto/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: itl3kizj with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0971233997861034\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_depth: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmin_child_weight: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_estimators: 478\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \treg_lambda: 1.187004446147595\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsubsample: 0.7698499456753943\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'xai-guided-cot' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/gauravpendharkar/xai-guided-cot/wandb/run-20251201_201924-itl3kizj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/gauravpendharkar/xai-guided-cot/runs/itl3kizj' target=\"_blank\">divine-sweep-4</a></strong> to <a href='https://wandb.ai/gauravpendharkar/xai-guided-cot' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/gauravpendharkar/xai-guided-cot/sweeps/yc32vi2s' target=\"_blank\">https://wandb.ai/gauravpendharkar/xai-guided-cot/sweeps/yc32vi2s</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/gauravpendharkar/xai-guided-cot' target=\"_blank\">https://wandb.ai/gauravpendharkar/xai-guided-cot</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/gauravpendharkar/xai-guided-cot/sweeps/yc32vi2s' target=\"_blank\">https://wandb.ai/gauravpendharkar/xai-guided-cot/sweeps/yc32vi2s</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/gauravpendharkar/xai-guided-cot/runs/itl3kizj' target=\"_blank\">https://wandb.ai/gauravpendharkar/xai-guided-cot/runs/itl3kizj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>accuracy_std</td><td>▁</td></tr><tr><td>f1_macro</td><td>▁</td></tr><tr><td>f1_macro_std</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.81554</td></tr><tr><td>accuracy_std</td><td>0.03343</td></tr><tr><td>f1_macro</td><td>0.80343</td></tr><tr><td>f1_macro_std</td><td>0.03509</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">divine-sweep-4</strong> at: <a href='https://wandb.ai/gauravpendharkar/xai-guided-cot/runs/itl3kizj' target=\"_blank\">https://wandb.ai/gauravpendharkar/xai-guided-cot/runs/itl3kizj</a><br> View project at: <a href='https://wandb.ai/gauravpendharkar/xai-guided-cot' target=\"_blank\">https://wandb.ai/gauravpendharkar/xai-guided-cot</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251201_201924-itl3kizj/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: w4juistf with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.06860036760191021\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_depth: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmin_child_weight: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_estimators: 363\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_state: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \treg_lambda: 1.8351968143525192\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsubsample: 0.72028470097465\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'xai-guided-cot' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/gauravpendharkar/xai-guided-cot/wandb/run-20251201_201929-w4juistf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/gauravpendharkar/xai-guided-cot/runs/w4juistf' target=\"_blank\">pretty-sweep-5</a></strong> to <a href='https://wandb.ai/gauravpendharkar/xai-guided-cot' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/gauravpendharkar/xai-guided-cot/sweeps/yc32vi2s' target=\"_blank\">https://wandb.ai/gauravpendharkar/xai-guided-cot/sweeps/yc32vi2s</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/gauravpendharkar/xai-guided-cot' target=\"_blank\">https://wandb.ai/gauravpendharkar/xai-guided-cot</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/gauravpendharkar/xai-guided-cot/sweeps/yc32vi2s' target=\"_blank\">https://wandb.ai/gauravpendharkar/xai-guided-cot/sweeps/yc32vi2s</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/gauravpendharkar/xai-guided-cot/runs/w4juistf' target=\"_blank\">https://wandb.ai/gauravpendharkar/xai-guided-cot/runs/w4juistf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>accuracy_std</td><td>▁</td></tr><tr><td>f1_macro</td><td>▁</td></tr><tr><td>f1_macro_std</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.81379</td></tr><tr><td>accuracy_std</td><td>0.04102</td></tr><tr><td>f1_macro</td><td>0.80039</td></tr><tr><td>f1_macro_std</td><td>0.04393</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">pretty-sweep-5</strong> at: <a href='https://wandb.ai/gauravpendharkar/xai-guided-cot/runs/w4juistf' target=\"_blank\">https://wandb.ai/gauravpendharkar/xai-guided-cot/runs/w4juistf</a><br> View project at: <a href='https://wandb.ai/gauravpendharkar/xai-guided-cot' target=\"_blank\">https://wandb.ai/gauravpendharkar/xai-guided-cot</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251201_201929-w4juistf/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed hyperparameter tuning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sorting runs by -summary_metrics.f1_macro\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model with best hyperparameters.\n",
      "Logged explanation data to data/dataset_config/titanic_config.json\n",
      "Explanation process completed.\n"
     ]
    }
   ],
   "source": [
    "clf = XGBClassifier()\n",
    "xmodel = ExplainableModel(\n",
    "    dataset=titanic_dataset,\n",
    "    estimator=clf\n",
    ")\n",
    "xmodel.explain(params_grid_file=\"data/tune_config/xgb.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b105a38",
   "metadata": {},
   "source": [
    "# Zero Shot Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ff4ce94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Titanic] Dropped 179 rows due to NaNs (kept 712 rows).\n",
      "KEY: baseline_unmasked_batch-0\n",
      "PROMPT:\n",
      " \n",
      "            You are a classifier for the tabular dataset 'titanic'.\n",
      "            Each example has features and a target label called 'Survived'.\n",
      "            Given the following feature values for one example, predict the label.\n",
      "            Return EXACTLY one of the following labels (just the value, no extra words):\n",
      "            1, 0\n",
      "\n",
      "            Here are the feature values:\n",
      "            Pclass: 1.0\n",
      "Sex: 1.0\n",
      "Age: 24.0\n",
      "SibSp: 0.0\n",
      "Parch: 0.0\n",
      "Fare: 69.3\n",
      "Embarked: 1.0\n",
      "\n",
      "            Question: What is the predicted value of 'Survived' for this example?\n",
      "\n",
      "            Note: Answer with exactly one of the allowed label values, nothing else.\n",
      "     \n",
      "---\n",
      "\n",
      "Saved batch file to: data/batches/titanic_baseline_batches.jsonl\n",
      "File data/batches/titanic_baseline_batches.jsonl uploaded to batch_inputs/gemini/titanic_baseline_batches.jsonl\n",
      "GCS URI: gs://6998final-bucket/batch_inputs/gemini/titanic_baseline_batches.jsonl\n",
      "Submitted Job: projects/372383421945/locations/us-east4/batchPredictionJobs/2120156660881162240\n",
      "Output base dir: gs://6998final-bucket/batch_outputs/gemini\n",
      "projects/372383421945/locations/us-east4/batchPredictionJobs/2120156660881162240 state: JobState.JOB_STATE_RUNNING\n",
      "projects/372383421945/locations/us-east4/batchPredictionJobs/2120156660881162240 state: JobState.JOB_STATE_RUNNING\n",
      "projects/372383421945/locations/us-east4/batchPredictionJobs/2120156660881162240 state: JobState.JOB_STATE_RUNNING\n",
      "projects/372383421945/locations/us-east4/batchPredictionJobs/2120156660881162240 state: JobState.JOB_STATE_RUNNING\n",
      "projects/372383421945/locations/us-east4/batchPredictionJobs/2120156660881162240 state: JobState.JOB_STATE_RUNNING\n",
      "projects/372383421945/locations/us-east4/batchPredictionJobs/2120156660881162240 state: JobState.JOB_STATE_RUNNING\n",
      "projects/372383421945/locations/us-east4/batchPredictionJobs/2120156660881162240 state: JobState.JOB_STATE_RUNNING\n",
      "projects/372383421945/locations/us-east4/batchPredictionJobs/2120156660881162240 state: JobState.JOB_STATE_RUNNING\n",
      "projects/372383421945/locations/us-east4/batchPredictionJobs/2120156660881162240 state: JobState.JOB_STATE_RUNNING\n",
      "projects/372383421945/locations/us-east4/batchPredictionJobs/2120156660881162240 state: JobState.JOB_STATE_SUCCEEDED\n",
      "Final state: JobState.JOB_STATE_SUCCEEDED\n",
      "Downloaded batch_outputs/gemini/prediction-model-2025-12-06T05:30:31.099333Z/predictions.jsonl to data/batch_outputs/titanic_baseline_predictions.jsonl.\n"
     ]
    }
   ],
   "source": [
    "model = Model(name=\"gemini-2.5-flash\", temperature=0.0, max_tokens= 512)\n",
    "baseline = ZeroShotBaseline(dataset=titanic_dataset, \n",
    "                            model=model, \n",
    "                            prompt_gen_fn=zero_shot_prompt_generator)\n",
    "baseline.create_batch_prompts()\n",
    "len(baseline.batches), baseline.batches[1]\n",
    "for b in baseline.batches[:1]:\n",
    "    print(\"KEY:\", b[\"key\"])\n",
    "    print(\"PROMPT:\\n\", b[\"request\"][\"contents\"][0][\"parts\"][0][\"text\"][:800], \"\\n---\\n\")\n",
    "baseline.save_batches_as_jsonl()\n",
    "print(\"Saved batch file to:\", baseline.output_file)\n",
    "baseline.upload_batches_to_gcs()\n",
    "print(\"GCS URI:\", baseline.gcp_uri)\n",
    "baseline.submit_batch_inference_job()\n",
    "baseline.download_job_outputs_from_gcs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39167fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Unmasked Results ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_id</th>\n",
       "      <th>test_idx</th>\n",
       "      <th>prediction</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>correct</th>\n",
       "      <th>finish_reason</th>\n",
       "      <th>completed</th>\n",
       "      <th>raw_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>641</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>STOP</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>496</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>STOP</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>262</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>STOP</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>311</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>STOP</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>551</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>STOP</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>138</td>\n",
       "      <td>362</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>STOP</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>139</td>\n",
       "      <td>56</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>STOP</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>140</td>\n",
       "      <td>137</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>STOP</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>141</td>\n",
       "      <td>651</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>STOP</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>142</td>\n",
       "      <td>74</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>STOP</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>143 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     batch_id  test_idx  prediction  ground_truth correct finish_reason  \\\n",
       "0           0       641         1.0             1    True          STOP   \n",
       "1           1       496         1.0             1    True          STOP   \n",
       "2           2       262         1.0             0   False          STOP   \n",
       "3           3       311         1.0             1    True          STOP   \n",
       "4           4       551         0.0             0    True          STOP   \n",
       "..        ...       ...         ...           ...     ...           ...   \n",
       "138       138       362         0.0             0    True          STOP   \n",
       "139       139        56         1.0             0   False          STOP   \n",
       "140       140       137         1.0             1    True          STOP   \n",
       "141       141       651         1.0             1    True          STOP   \n",
       "142       142        74         0.0             1   False          STOP   \n",
       "\n",
       "     completed raw_output  \n",
       "0            1          1  \n",
       "1            1          1  \n",
       "2            1          1  \n",
       "3            1          1  \n",
       "4            1          0  \n",
       "..         ...        ...  \n",
       "138          1          0  \n",
       "139          1          1  \n",
       "140          1          1  \n",
       "141          1          1  \n",
       "142          1          0  \n",
       "\n",
       "[143 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Masked Results ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_id</th>\n",
       "      <th>test_idx</th>\n",
       "      <th>prediction</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>correct</th>\n",
       "      <th>finish_reason</th>\n",
       "      <th>completed</th>\n",
       "      <th>raw_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>641</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>STOP</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>496</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>MAX_TOKENS</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>262</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>STOP</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>311</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>MAX_TOKENS</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>551</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>STOP</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>138</td>\n",
       "      <td>362</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>STOP</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>139</td>\n",
       "      <td>56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>MAX_TOKENS</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>140</td>\n",
       "      <td>137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>STOP</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>141</td>\n",
       "      <td>651</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>MAX_TOKENS</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>142</td>\n",
       "      <td>74</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>STOP</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>143 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     batch_id  test_idx  prediction  ground_truth correct finish_reason  \\\n",
       "0           0       641         1.0             1    True          STOP   \n",
       "1           1       496         NaN             1    None    MAX_TOKENS   \n",
       "2           2       262         0.0             0    True          STOP   \n",
       "3           3       311         NaN             1    None    MAX_TOKENS   \n",
       "4           4       551         0.0             0    True          STOP   \n",
       "..        ...       ...         ...           ...     ...           ...   \n",
       "138       138       362         0.0             0    True          STOP   \n",
       "139       139        56         NaN             0    None    MAX_TOKENS   \n",
       "140       140       137         0.0             1   False          STOP   \n",
       "141       141       651         NaN             1    None    MAX_TOKENS   \n",
       "142       142        74         0.0             1   False          STOP   \n",
       "\n",
       "     completed raw_output  \n",
       "0            1          1  \n",
       "1            0             \n",
       "2            1          0  \n",
       "3            0             \n",
       "4            1          0  \n",
       "..         ...        ...  \n",
       "138          1          0  \n",
       "139          0             \n",
       "140          1          0  \n",
       "141          0             \n",
       "142          1          0  \n",
       "\n",
       "[143 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Summary ===\n",
      "\n",
      "UNMASKED:\n",
      "  total: 143\n",
      "  completed: 141\n",
      "  correct: 102\n",
      "  accuracy: 0.713\n",
      "  accuracy_of_completed: 0.723\n",
      "\n",
      "MASKED:\n",
      "  total: 143\n",
      "  completed: 122\n",
      "  correct: 86\n",
      "  accuracy: 0.601\n",
      "  accuracy_of_completed: 0.705\n"
     ]
    }
   ],
   "source": [
    "results_path = f\"data/batch_outputs/titanic_baseline_predictions.jsonl\"\n",
    "unmasked_df, masked_df = parse_baseline_llm_results(\n",
    "    results_jsonl_path=results_path, config_file_path=\"data/dataset_config/titanic_config.json\"\n",
    ")\n",
    "with pd.option_context(\"display.max_rows\", 40, \"display.width\", None):\n",
    "    print(\"=== Unmasked Results ===\")\n",
    "    display(unmasked_df)\n",
    "\n",
    "    print(\"\\n=== Masked Results ===\")\n",
    "    display(masked_df)\n",
    "\n",
    "\n",
    "# Get summary statistics\n",
    "summary = summarize_baseline_results(unmasked_df, masked_df)\n",
    "print(\"\\n=== Summary ===\")\n",
    "for name, stats in summary.items():\n",
    "    print(f\"\\n{name.upper()}:\")\n",
    "    for k, v in stats.items():\n",
    "        print(f\"  {k}: {v:.3f}\" if isinstance(v, float) else f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd833cc9",
   "metadata": {},
   "source": [
    "# Reason Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "199ed285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found best number of clusters: k=3 with silhouette score: 0.2747174239109675\n",
      "Chosen 3 diverse examples.\n",
      "[Titanic] Dropped 179 rows due to NaNs (kept 712 rows).\n"
     ]
    }
   ],
   "source": [
    "reasoning_model = Model(\n",
    "    name=\"deepseek-ai/DeepSeek-R1\",\n",
    "    temperature=0.6,\n",
    "    max_tokens=4096\n",
    ")\n",
    "\n",
    "rg = ReasonGenerator(\n",
    "    dataset=titanic_dataset,\n",
    "    model=reasoning_model,\n",
    "    prompt_gen_fn=reasoning_generator_prompt\n",
    ")\n",
    "\n",
    "rg.create_batch_prompts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df00a213",
   "metadata": {},
   "outputs": [],
   "source": [
    "rg.save_batches_as_jsonl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c457c421",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading file titanic_reasoning_batches.jsonl: 100%|██████████| 6.40k/6.40k [00:00<00:00, 10.2kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Status: BatchJobStatus.IN_PROGRESS\n",
      "Current Status: BatchJobStatus.IN_PROGRESS\n",
      "Current Status: BatchJobStatus.IN_PROGRESS\n",
      "Current Status: BatchJobStatus.IN_PROGRESS\n",
      "Current Status: BatchJobStatus.IN_PROGRESS\n",
      "Current Status: BatchJobStatus.IN_PROGRESS\n",
      "Current Status: BatchJobStatus.IN_PROGRESS\n",
      "Current Status: BatchJobStatus.IN_PROGRESS\n",
      "Current Status: BatchJobStatus.IN_PROGRESS\n",
      "Current Status: BatchJobStatus.IN_PROGRESS\n",
      "Current Status: BatchJobStatus.IN_PROGRESS\n",
      "Current Status: BatchJobStatus.IN_PROGRESS\n",
      "Current Status: BatchJobStatus.IN_PROGRESS\n",
      "Current Status: BatchJobStatus.IN_PROGRESS\n",
      "Current Status: BatchJobStatus.IN_PROGRESS\n",
      "Current Status: BatchJobStatus.COMPLETED\n",
      "Batch completed successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file titanic_reasoning_predictions.jsonl: 100%|██████████| 20.4k/20.4k [00:00<00:00, 5.88MB/s]\n"
     ]
    }
   ],
   "source": [
    "rg.submit_batches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2790c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_jsonl_path = f\"data/batch_outputs/{titanic_dataset.name}_reasoning_predictions.jsonl\"\n",
    "results = []\n",
    "with open(results_jsonl_path, 'r') as f:\n",
    "    for line in f:\n",
    "        results.append(json.loads(line.strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866f7c0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{862: \"The model correctly predicts survival (1) for this passenger, matching the ground truth label (1.0). The prediction is primarily driven by two dominant features: **Sex** (SHAP +2.37) and **Pclass** (SHAP +1.97). The high positive SHAP value for Sex=1.0 (likely indicating female, as females had higher survival rates) strongly increases survival probability, consistent with the dataset's top feature importance (0.44). Similarly, Pclass=1.0 (first class) contributes significantly to survival due to prioritized evacuation. Supporting features like **Fare** (SHAP +0.21, moderate cost aligning with first-class status) and **SibSp=0.0** (SHAP +0.10, no siblings/spouses competing for resources) provide additional positive contributions. Although **Age=48.0** (SHAP +0.05) slightly favors survival (possibly due to adulthood and evacuation priority), and **Parch=0.0** (SHAP -0.02, no children/parents) has a negligible negative effect, their impacts are dwarfed by the advantages of Sex and Pclass. The collective SHAP values sum to a strong net positive effect, decisively pushing the prediction toward survival.\",\n",
       " 147: \"The model correctly predicted non-survival (0), matching the ground truth. Key factors driving this prediction include the passenger's third-class status (Pclass=3), which contributed strongly negatively (-2.249) due to reduced survival rates in lower classes. Although being female (Sex=1) and young (Age=9) provided substantial positive contributions (+1.388 and +1.251 respectively, reflecting survival advantages for women and children), these were outweighed by other detrimental factors: traveling with two siblings/spouses (SibSp=2) reduced probability (-0.470), the fare amount (-0.717) may indicate an expensive but still disadvantaged third-class ticket, and embarkation location (Embarked=0) had a minor negative effect (-0.199). The cumulative SHAP value is negative (-0.658), indicating that the combined features pulled the prediction below the model's baseline survival probability, resulting in a non-survival classification despite some protective characteristics.\",\n",
       " 302: 'The model correctly predicted that the passenger survival status (Survived: 0) based on key features and their SHAP contributions. The strongest negative influences came from Sex (SHAP: -1.32) and Pclass (SHAP: -0.83), where Sex=0 (male) and Pclass=3 (third class) significantly reduced survival probability, aligning with historical patterns of lower survival for males and lower socioeconomic classes. Age=19 (SHAP: -0.58) further decreased survival likelihood as young adults had reduced priority during evacuation. Minor negative contributions from SibSp=0 (no siblings/spouses), Parch=0 (no parents/children), and Embarked=0 (likely Southampton) compounded this effect. Although Fare=0 had a negligible positive SHAP value (0.004), its impact was dwarfed by other features. The cumulative effect of these negative SHAP values—particularly the dominant influences of Sex and Pclass—strongly pushed the prediction toward non-survival (0), matching the ground truth label.'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_reasoning_llm_results(results_jsonl_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19667d45",
   "metadata": {},
   "source": [
    "# LLM as Judge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b1e3d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_jsonl_path = f\"data/batch_outputs/{titanic_dataset.name}_reasoning_predictions.jsonl\"\n",
    "reasoning = parse_reasoning_llm_results(results_jsonl_path)\n",
    "objective_judge_model = Model(\n",
    "    name=\"claude-haiku-4-5\",\n",
    "    temperature=0.6,\n",
    "    max_tokens=4096\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab7c97df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Titanic] Dropped 179 rows due to NaNs (kept 712 rows).\n"
     ]
    }
   ],
   "source": [
    "judge = ObjectiveJudge(\n",
    "    dataset=titanic_dataset,\n",
    "    model=objective_judge_model,\n",
    "    prompt_gen_fn=objective_judge_prompt_generator\n",
    ")\n",
    "\n",
    "judge.create_batch_prompts(reasoning=reasoning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "536ee026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ROLE:\n",
      "You are an expert, objective judge for the tabular dataset 'titanic'.\n",
      "Your role is to assess the faithfulness and quality of the model's reasoning against the provided data.\n",
      "Each example has features and a target label called 'Survived'.\n",
      "\n",
      "--- INPUT DATA ---\n",
      "Here are the **Feature Values** for this specific example:\n",
      "Survived: 1.0\n",
      "Pclass: 1.0\n",
      "Sex: 1.0\n",
      "Age: 48.0\n",
      "SibSp: 0.0\n",
      "Parch: 0.0\n",
      "Fare: 25.9292\n",
      "Embarked: 0.0\n",
      "\n",
      "Here are the **SHAP Values** (the source of truth for feature contribution):\n",
      "Pclass: 1.9708366\n",
      "Sex: 2.3702703\n",
      "Age: 0.051405907\n",
      "SibSp: 0.10275364\n",
      "Parch: -0.019484863\n",
      "Fare: 0.21362345\n",
      "Embarked: 0.028390752\n",
      "\n",
      "Here are the overall **Feature Importances** (Global context):\n",
      "Pclass: 0.21643278002738953\n",
      "Sex: 0.4413147568702698\n",
      "Age: 0.07450001686811447\n",
      "SibSp: 0.07695005089044571\n",
      "Parch: 0.054212767630815506\n",
      "Fare: 0.06814616173505783\n",
      "Embarked: 0.0684434026479721\n",
      "\n",
      "The model predicted: 1\n",
      "The ground truth label is: 1.0\n",
      "\n",
      "Here is the **Model's Reasoning** for its prediction:\n",
      "The model correctly predicts survival (1) for this passenger, matching the ground truth label (1.0). The prediction is primarily driven by two dominant features: **Sex** (SHAP +2.37) and **Pclass** (SHAP +1.97). The high positive SHAP value for Sex=1.0 (likely indicating female, as females had higher survival rates) strongly increases survival probability, consistent with the dataset's top feature importance (0.44). Similarly, Pclass=1.0 (first class) contributes significantly to survival due to prioritized evacuation. Supporting features like **Fare** (SHAP +0.21, moderate cost aligning with first-class status) and **SibSp=0.0** (SHAP +0.10, no siblings/spouses competing for resources) provide additional positive contributions. Although **Age=48.0** (SHAP +0.05) slightly favors survival (possibly due to adulthood and evacuation priority), and **Parch=0.0** (SHAP -0.02, no children/parents) has a negligible negative effect, their impacts are dwarfed by the advantages of Sex and Pclass. The collective SHAP values sum to a strong net positive effect, decisively pushing the prediction toward survival.\n",
      "\n",
      "--- EVALUATION RUBRICS ---\n",
      "You must perform a detailed analysis.\n",
      "\n",
      "### METRICS TO SCORE:\n",
      "**Score on a 1.00 to 5.00 scale using only 0.25 increments (e.g., 4.00, 4.25, 4.50, 4.75, 5.00), where 5.00 is best.**\n",
      "\n",
      "1. **Faithfulness:** How accurately does the reasoning reflect the **sign** (direction) and **relative magnitude** of the SHAP values? Score 1.00 if the reasoning contradicts the major SHAP values.\n",
      "2. **Consistency:** Does the reasoning focus on the features with the **highest absolute SHAP values** (most influential features) and prioritize them correctly?\n",
      "3. **Coherence:** Is the reasoning grammatically sound, well-structured, and easy for a non-expert to understand?\n",
      "\n",
      "--- OUTPUT FORMAT ---\n",
      "You must first output the full **Chain of Thought (CoT)**, explaining your scoring decisions. Immediately after your CoT, provide the structured JSON metrics block. **DO NOT generate any text, commentary, or markdown fences after the final closing brace of the JSON object.**\n",
      "\n",
      "[Your detailed Chain of Thought goes here, incorporating all justification for the scores...]\n",
      "\n",
      "Evaluation:\n",
      "{\n",
      "    \"metrics\": {\n",
      "        \"faithfulness\": [1.00 to 5.00 in 0.25 increments],\n",
      "        \"consistency\": [1.00 to 5.00 in 0.25 increments],\n",
      "        \"coherence\": [1.00 to 5.00 in 0.25 increments]\n",
      "    }\n",
      "}\n",
      "\n",
      "THE JSON OBJECT MUST BE PRECEDED BY \"EVALUATION:\" VERBATIM. NO EXTRA TEXT BEYOND THE JSON OBJECT.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(judge.batches[0][\"params\"][\"messages\"][0][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da89fad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch with id: msgbatch_01A6bvfAv4UFBPjSTjaRWWRq\n",
      "Batch msgbatch_01A6bvfAv4UFBPjSTjaRWWRq is still processing...\n",
      "Batch msgbatch_01A6bvfAv4UFBPjSTjaRWWRq has completed processing.\n",
      "Batch result types: {'succeeded': 3, 'errored': 0, 'expired': 0}\n",
      "Saved evaluations to data/batch_outputs/titanic_objective_judge_evaluations.jsonl\n"
     ]
    }
   ],
   "source": [
    "judge.submit_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d66b3dd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{862: {'faithfulness': 4.75, 'consistency': 4.75, 'coherence': 4.75},\n",
       " 147: {'faithfulness': 4.75, 'consistency': 4.75, 'coherence': 4.75},\n",
       " 302: {'faithfulness': 4.75, 'consistency': 4.75, 'coherence': 4.75}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scripts.postprocess import parse_objective_judge_results\n",
    "\n",
    "results_jsonl_path = f\"data/batch_outputs/{titanic_dataset.name}_objective_judge_evaluations.jsonl\"\n",
    "\n",
    "parse_objective_judge_results(results_jsonl_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a777a686",
   "metadata": {},
   "source": [
    "# CoT-based Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f267709",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "6998final",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
