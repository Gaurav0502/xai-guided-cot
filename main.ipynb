{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec8bc181",
   "metadata": {},
   "source": [
    "# Explanability-Driven In-context Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cada729a",
   "metadata": {},
   "source": [
    "# Importing the required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f52666b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hongyili/anaconda3/envs/6998final/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# modules used for data handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "\n",
    "# custom preprocessing modules\n",
    "from scripts.preprocess import preprocess_titanic\n",
    "\n",
    "# modules used for model handling\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# modules used for genari pipeline\n",
    "from scripts.pipeline import Pipeline\n",
    "from scripts.configs import Dataset, Model\n",
    "\n",
    "# modules used for env variables\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "WANDB_API_KEY = os.getenv(\"WANDB_API_KEY\")\n",
    "WANDB_PROJECT_NAME = os.getenv(\"WANDB_PROJECT_NAME\")\n",
    "PROJECT_NAME = os.getenv(\"PROJECT_NAME\")\n",
    "BUCKET_NAME = os.getenv(\"BUCKET_NAME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388546a1",
   "metadata": {},
   "source": [
    "## Default Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3bf4712",
   "metadata": {},
   "outputs": [],
   "source": [
    "explanable_model = XGBClassifier()\n",
    "tune_config_file = \"data/tune_config/xgb.json\"\n",
    "reasoning_gen_model = Model(\n",
    "    provider=\"together\",\n",
    "    name = \"deepseek-ai/DeepSeek-R1\",\n",
    "    temperature=0.6,\n",
    "    max_tokens=4096\n",
    ")\n",
    "objective_judge_model = Model(\n",
    "    provider=\"anthropic\",\n",
    "    name=\"claude-haiku-4-5\",\n",
    "    temperature=0.6,\n",
    "    max_tokens=4096\n",
    ")\n",
    "cot_model = Model(\n",
    "    provider=\"google\",\n",
    "    name=\"gemini-2.5-flash\",\n",
    "    temperature=0.0,\n",
    "    max_tokens=4096\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d5695d",
   "metadata": {},
   "source": [
    "## Test Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2890b3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(\n",
    "    name=\"titanic\",\n",
    "    path=\"data/datasets/titanic_small.csv\",\n",
    "    config_file_path=\"data/dataset_config/titanic_config.json\",\n",
    "    shap_vals_path=\"data/shap_values/titanic_shap.csv\",\n",
    "    preprocess_fn=preprocess_titanic,\n",
    "    target_col=\"Survived\",\n",
    "    labels={0: \"Did not survive\", 1: \"Survived\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "511432a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Pipeline(\n",
    "    dataset=dataset,\n",
    "    explanable_model=explanable_model,\n",
    "    tune_config_file=tune_config_file,\n",
    "    reasoning_gen_model=reasoning_gen_model,\n",
    "    objective_judge_model=objective_judge_model,\n",
    "    cot_model=cot_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ce42c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Titanic] Dropped 179 rows due to NaNs (kept 712 rows).\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/tune_config/xgb.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mllm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobjective_judge\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcot_ablation\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Columbia/Courses/COMS6998GENAI/project/xai-guided-cot/scripts/pipeline.py:154\u001b[39m, in \u001b[36mPipeline.run\u001b[39m\u001b[34m(self, baseline, objective_judge, cot_ablation)\u001b[39m\n\u001b[32m    143\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, \n\u001b[32m    144\u001b[39m         baseline: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    145\u001b[39m         objective_judge: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    148\u001b[39m     \u001b[38;5;66;03m# xai model training\u001b[39;00m\n\u001b[32m    149\u001b[39m     \u001b[38;5;66;03m# and tuning\u001b[39;00m\n\u001b[32m    150\u001b[39m     xai_model = ExplainableModel(\n\u001b[32m    151\u001b[39m         dataset=\u001b[38;5;28mself\u001b[39m.dataset,\n\u001b[32m    152\u001b[39m         estimator=\u001b[38;5;28mself\u001b[39m.explanable_model\n\u001b[32m    153\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m     \u001b[43mxai_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexplain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_grid_file\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtune_config_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    156\u001b[39m     \u001b[38;5;66;03m# baseline computations\u001b[39;00m\n\u001b[32m    157\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m baseline:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Columbia/Courses/COMS6998GENAI/project/xai-guided-cot/scripts/explanable_tree_model.py:147\u001b[39m, in \u001b[36mExplainableModel.explain\u001b[39m\u001b[34m(self, params_grid_file)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mexplain\u001b[39m(\u001b[38;5;28mself\u001b[39m, params_grid_file: \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__tune\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_grid_file\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams_grid_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    148\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m[XAI-MODEL] Completed hyperparameter tuning.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    149\u001b[39m     \u001b[38;5;28mself\u001b[39m.__train_model()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Columbia/Courses/COMS6998GENAI/project/xai-guided-cot/scripts/explanable_tree_model.py:96\u001b[39m, in \u001b[36mExplainableModel.__tune\u001b[39m\u001b[34m(self, params_grid_file)\u001b[39m\n\u001b[32m     94\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__tune\u001b[39m(\u001b[38;5;28mself\u001b[39m, params_grid_file: \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m96\u001b[39m     sweep_config = json.load(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mparams_grid_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[32m     98\u001b[39m     \u001b[38;5;28mself\u001b[39m.sweep_id = wandb.sweep(sweep_config, project=\u001b[38;5;28mself\u001b[39m.project_name)\n\u001b[32m     99\u001b[39m     wandb.agent(\u001b[38;5;28mself\u001b[39m.sweep_id, function=\u001b[38;5;28mself\u001b[39m.__train_sweep, \n\u001b[32m    100\u001b[39m                 count=sweep_config.get(\u001b[33m\"\u001b[39m\u001b[33mcount\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m10\u001b[39m))\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'data/tune_config/xgb.json'"
     ]
    }
   ],
   "source": [
    "llm.run(baseline=True, objective_judge=True, cot_ablation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b87b6ad0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'zero_shot_baseline': {'xgboost': {'accuracy': 0.8484848484848485,\n",
       "   'macro_f1_score': 0.8331648129423661},\n",
       "  'zero-shot-prompting': {'macro_f1_score': 0.7954545454545454,\n",
       "   'accuracy': 0.8181818181818182}},\n",
       " 'zero_shot_cot_ablation': {'xgboost': {'accuracy': 0.8484848484848485,\n",
       "   'macro_f1_score': 0.8331648129423661},\n",
       "  'zero-shot-cot': {'macro_f1_score': 0.5909090909090909,\n",
       "   'accuracy': 0.6363636363636364}},\n",
       " 'reasoning': {60: 'The model correctly predicts that the passenger did not survive (predicted label 0 matches ground truth 0.0). The SHAP values reveal that the strongest negative contributions come from Sex (0.0, male) at -1.49 and Pclass (3.0, third class) at -0.996, aligning with historical trends where males and lower-class passengers had lower survival rates. Age (21.0) further reduces survival probability with a SHAP of -0.312, as young adult males were less prioritized during evacuation. Although having no siblings/spouses (SibSp=0.0) contributes positively (SHAP +0.446), this is outweighed by the dominant negative features. Minor contributions from Parch, Fare, and Embarked do not alter the outcome. Cumulatively, these factors—especially high-impact features like Sex (global importance 0.552) and Pclass (0.117)—drive the prediction toward non-survival, resulting in a total SHAP value of approximately -2.376, which strongly suppresses the log-odds below the decision threshold.',\n",
       "  80: \"The model correctly predicts non-survival (0) for this passenger. The key negative contributors are Sex (male, SHAP = -1.318) and Pclass (3rd class, SHAP = -1.302), which align with historical patterns where males and lower-class passengers had reduced survival odds. These are further reinforced by SibSp (4 siblings/spouses, SHAP = -0.747), indicating a large family likely in third class, and Fare (39.69, SHAP = -0.455), which may reflect a group ticket cost rather than luxury. The positive influence of Age (16 years, SHAP = +0.778) partially offsets this, as younger passengers had higher priority, but not sufficiently to overcome the cumulative negative impact. Minor contributions from Parch (1 parent/child, SHAP = +0.133) and Embarked (Southampton, SHAP = +0.036) were negligible. The net SHAP sum (-2.875) strongly shifts the prediction away from survival, consistent with the passenger's actual fate.\",\n",
       "  59: 'The model correctly predicted survival (label 1) for this passenger, aligning with the ground truth label of 1.0. The prediction is driven primarily by the passenger\\'s gender (Sex=1.0, female), which has the highest SHAP value (2.08) and is the most important feature globally (importance 0.55), strongly favoring survival due to the \"women and children first\" protocol. The age of 19 years (SHAP 0.86) further supports survival, as young adults had better mobility. Having no siblings/spouses (SibSp=0.0, SHAP 0.46) also contributed positively, potentially enabling faster evacuation. Although third-class travel (Pclass=3.0, SHAP -1.22) significantly reduced survival chances due to restricted lifeboat access, the combined positive effects of gender, age, and SibSp outweighed this negative factor. Minor contributions from fare (SHAP 0.19) and negligible impacts from Parch (SHAP -0.01) and Embarked (SHAP -0.07) did not alter the outcome. Overall, the net SHAP value of approximately 2.29 decisively pushed the prediction above the threshold for survival.',\n",
       "  134: \"The model predicted non-survival (0) for this passenger, contrasting with the ground truth survival (1). Key feature contributions were analyzed using SHAP values, where positive values increase survival likelihood and negative values decrease it. The passenger's male gender (Sex=0) contributed strongly against survival (-1.40 SHAP), consistent with historical evacuation priorities. Being 49 years old (Age) further reduced survival probability (-0.93 SHAP), as adults had lower rescue priority. While 1st-class status (Pclass=1) strongly favored survival (+1.74 SHAP) and the higher fare (Fare=56.93) provided moderate support (+0.80 SHAP), these positive factors were insufficient to offset the substantial negative impact of gender and age. Embarkation location (Embarked=1) and family size features (SibSp=1, Parch=0) provided minor negative contributions. The cumulative SHAP effect was negative (-0.26), overwhelming the baseline survival probability and resulting in a non-survival prediction. This misprediction suggests the model overemphasized demographic risk factors despite countervailing privileges from higher socioeconomic status in this case.\",\n",
       "  78: \"The model correctly predicted that the passenger did not survive (predicted label 0 matches ground truth 0.0). Key contributions came from the passenger's age (38 years), which strongly reduced survival likelihood with a SHAP value of -1.8259, and fare (13 units), which further decreased survival probability with a SHAP value of -0.6094. Although the passenger being male (Sex=1.0) contributed positively (SHAP: +2.1648)—an unexpected effect given historical context—this was outweighed by the strong negative impacts of age and fare, along with smaller negative contributions from Pclass (2nd class, SHAP: -0.0325) and Parch (no children/parents, SHAP: -0.0630). The cumulative effect of these factors, particularly the dominant negative influence of age, resulted in the model's prediction of non-survival.\",\n",
       "  16: \"The model correctly predicted survival (1) for this passenger, aligning with the ground truth label (1.0). The prediction is driven by the combined SHAP contributions: First-class travel (Pclass=1.0) provides the strongest positive push (+1.87) due to priority evacuation access. Though being male (Sex=0.0) reduces survival likelihood (-1.39), this is counterbalanced by the high fare paid (Fare=52.55, +0.95), indicating luxury-class resources. The passenger's age (42.0) contributes moderately positively (+0.49), possibly reflecting prime-age resilience. Embarkation port (Embarked=0.0, likely Cherbourg) adds a minor survival boost (+0.20). While traveling with one sibling/spouse (SibSp=1.0, -0.12) and no parents/children (Parch=0.0, -0.05) slightly reduce odds, the net SHAP sum (≈1.96) decisively favors survival. The aggregate effect of premium travel conditions (Pclass, Fare) outweighs gender-based risks, resulting in the correct survival prediction.\",\n",
       "  41: 'The model correctly predicted that the passenger did not survive (label 0), aligning with the ground truth. Key features driving this prediction include Sex (0.0, male) and Pclass (3.0, third class), which had the strongest negative SHAP values (-1.303 and -1.026, respectively), heavily reducing survival probability. These features are the most globally important (Sex importance: 0.552, Pclass: 0.117). Additional negative contributions came from SibSp (1.0, -0.738 SHAP) and Fare) (7.0458, -0.261 SHAP), reflecting the risk associated with traveling with siblings/spouses and low ticket cost. Though Age (29.0) and Embarked (0.0) provided slight positive SHAP values (0.146 and 0.155), they were insufficient to offset the dominant negative influences. The cumulative effect of these factors—particularly male gender and third-class status—resulted in a clear prediction of non-survival.'},\n",
       " 'llm_as_judge': {60: {'faithfulness': 5.0,\n",
       "   'consistency': 5.0,\n",
       "   'coherence': 5.0},\n",
       "  80: {'faithfulness': 5.0, 'consistency': 5.0, 'coherence': 5.0},\n",
       "  59: {'faithfulness': 5.0, 'consistency': 5.0, 'coherence': 5.0},\n",
       "  134: {'faithfulness': 5.0, 'consistency': 4.75, 'coherence': 4.75},\n",
       "  78: {'faithfulness': 4.5, 'consistency': 4.0, 'coherence': 4.75},\n",
       "  16: {'faithfulness': 5.0, 'consistency': 4.75, 'coherence': 4.75},\n",
       "  41: {'faithfulness': 4.75, 'consistency': 4.75, 'coherence': 4.75}},\n",
       " 'cot': {'xgboost': {'accuracy': 0.8484848484848485,\n",
       "   'macro_f1_score': 0.8331648129423661},\n",
       "  'xai-guided-cot': {'macro_f1_score': 0.7847157502329916,\n",
       "   'accuracy': 0.7878787878787878}}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db1ec42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "6998final",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
